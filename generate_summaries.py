import argparse
import json
import os
from typing import Any

import anthropic
import google.generativeai as genai
import pandas as pd
from openai import OpenAI


def get_client(
    provider: str, model: str, api_key_file: str | None
) -> OpenAI | genai.GenerativeModel | anthropic.Anthropic:
    if api_key_file is not None:
        with open(api_key_file, "r") as f:
            api_key = f.read().strip()

    if provider == "Google":
        genai.configure(api_key=os.environ["GOOGLE_API_KEY"] if api_key_file is None else api_key)
        return genai.GenerativeModel(model_name=model)

    elif provider == "OpenAI":
        return OpenAI(api_key=os.environ["OPENAI_API_KEY"] if api_key_file is None else api_key)

    elif provider == "Antropic":
        return anthropic.Anthropic(
            # もし環境変数でAPIキーをセットできなければここで指定:
            api_key=os.environ["CLAUDE_API_KEY"] if api_key_file is None else api_key
        )

    else:
        raise ValueError(f"Invalid provider {provider} was selected")


def get_google_summaries(
    client: genai.GenerativeModel,
    template: str,
    article: str,
    human_summary: str,
    ai_summary: str,
) -> dict[str, str]:
    filled_template = template.format(article=article, human_summary=human_summary, ai_summary=ai_summary)
    respone_length = 0
    while respone_length != 4:
        response = client.generate_content(filled_template)

        low_coherence_summaries = {
            f"Coherence {i}": text.strip()
            for i, text in zip([1, 3, 5, 7], response.text.split("\n\n\n"))  # type: ignore
        }

        respone_length = len(low_coherence_summaries)

    return low_coherence_summaries


def get_claude_summaries(
    client: anthropic.Anthropic,
    template: str,
    article: str,
    human_summary: str,
    ai_summary: str,
    model: str = "gpt-4o",
) -> dict[str, str]:
    filled_template = template.format(article=article, human_summary=human_summary, ai_summary=ai_summary)
    respone_length = 0
    while respone_length != 4:
        message = client.messages.create(
            max_tokens=4096,
            model=model,
            messages=[{"role": "user", "content": filled_template}],
        )

        low_coherence_summaries = {
            f"Coherence {i}": text.strip()
            for i, text in zip([1, 3, 5, 7], message.content[0].text.split("\n\n\n"))  # type: ignore
        }

        respone_length = len(low_coherence_summaries)

    return low_coherence_summaries


def get_openai_summaries(
    client: OpenAI,
    template: str,
    article: str,
    human_summary: str,
    ai_summary: str,
    model: str = "gpt-4o",
) -> dict[str, str]:
    filled_template = template.format(article=article, human_summary=human_summary, ai_summary=ai_summary)
    respone_length = 0
    while respone_length != 4:
        response = client.chat.completions.create(
            model=model,
            messages=[
                {
                    "role": "user",
                    "content": filled_template,
                }
            ],
            stream=False,
        )

        low_coherence_summaries = {
            f"Coherence {i}": text.strip()
            for i, text in zip(
                [1, 3, 5, 7],
                response.choices[0].message.content.split("\n\n\n"),  # type: ignore
            )
        }

        respone_length = len(low_coherence_summaries)

    return low_coherence_summaries


def main(args: argparse.Namespace) -> None:
    with open(args.input_path) as fd:
        summary_data: list[dict[str, Any]] = [json.loads(line) for line in fd.readlines()]

    with open(args.template_path) as fd:
        template = fd.read()

    client = get_client(args.provider, args.model, args.api_key_file)

    df: pd.DataFrame = pd.DataFrame(
        columns=[
            "Article",
            "Summary",
            "AI Summary",
            "Coherence 1",
            "Coherence 3",
            "Coherence 5",
            "Coherence 7",
        ]
    )

    for i, summary in enumerate(summary_data):
        article = summary["text_raw"]
        ai_summary = (
            f"""Here is a summary that was initially generated by an LLM:
                {summary["metadata"]["ai_summary"]}
            """
            if "ai_summary" in summary["metadata"]
            else ""
        )
        human_summary = summary["summary"]

        if isinstance(client, OpenAI):
            low_coherence_summaries = get_openai_summaries(
                client, template, article, human_summary, ai_summary, args.model
            )
        elif isinstance(client, genai.GenerativeModel):
            low_coherence_summaries = get_openai_summaries(client, template, article, human_summary, ai_summary)
        elif isinstance(client, anthropic.Anthropic):
            low_coherence_summaries = get_claude_summaries(
                client, template, article, human_summary, ai_summary, args.model
            )

        row = {
            "Article": article,
            "Summary": human_summary,
            "AI Summary": summary["metadata"]["ai_summary"] if "ai_summary" in summary["metadata"] else "",
        } | low_coherence_summaries

        df = pd.concat([df, pd.DataFrame([row])], axis=0, ignore_index=True)
        if i == 100:
            df.to_csv(
                os.path.join(f"{args.output_path}", f"{args.provider}-{args.model}.csv"),
                index=False,
            )
            raise ValueError


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--input-path",
        "-i",
        type=str,
        required=True,
        help="Path to the JSONL summary file",
    )
    parser.add_argument(
        "--output-path",
        "-o",
        type=str,
        required=True,
        help="Path to save the generated summaries",
    )
    parser.add_argument("--template-path", "-t", required=True, type=str, help="Path to the template")
    parser.add_argument(
        "--provider",
        "-p",
        type=str,
        default="OpenAI",
        choices=["OpenAI", "Google", "Claude"],
    )
    parser.add_argument(
        "--model",
        "-m",
        required=False,
        type=str,
        default="gpt-4o",
        help="Which GPT model to use for generation",
    )
    parser.add_argument("--api-key-file", type=str, help="Path to the file containing the API key")
    args = parser.parse_args()
    main(args)
